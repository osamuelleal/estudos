{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Biblioteca Pandas**\n",
    "\n",
    "- O Pandas é uma biblioteca Open Source\n",
    "\n",
    "- Esta biblioteca facilita a manipulação de conjuntos de dados não estruturados\n",
    "\n",
    "- Permite manipular arquivos de texto, com tipos de dados de diferentes tipos inclusive arquivos .jason\n",
    "\n",
    "- Biblioteca faz tarefas complexas se tornarem fáceis\n",
    "\n",
    "- Principal biblioteca Python para Análise de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conhecendo o dataframe pandas\n",
    "# Importando o Pandas\n",
    "\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo uma base de dados no formato .csv\n",
    "# O parâmetro sep é usado para definir qual o operador entre os dados\n",
    "# O parâmetro Header informa qual linha está minhas colunas ou se elas não existem\n",
    "# Se não existem colunas (header=none) o Pandas dará um número para cada atributo da base\n",
    "\n",
    "arquivo = 'C:/Users/Pc Trabalho/Desktop/Studio Sun/Estudo/DSZ/mdrepo-master/kc_house_data.csv'\n",
    "dataset = pd.read_csv (arquivo, ',' , header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimindo o tipo da variável dataset\n",
    "\n",
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método head() imprime as 5 primeiras linhas do dataframe\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O parâmetro index_col informa a coluna na qual o dataframe será indexado\n",
    "\n",
    "dataset = pd.read_csv (arquivo, ',', index_col='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para informar quais colunas queremos, usamos usecols=\n",
    "\n",
    "dataset = pd.read_csv (arquivo, ',', usecols= ['id', 'date', 'price', 'bedrooms'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimindo as 100 primeiras linhas do dataset\n",
    "\n",
    "dataset.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atributo columns retorna o nome das colunas do dataframe\n",
    "\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método count() retorna a quantidade de linhas de todas as colunas\n",
    "\n",
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O método describe() exibe informações estatísticas da base de dados\n",
    "# Várias informações como desvio de padrão, média, valor mínimo e máximo de colunas\n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime as 5 últimas linhas do arquivo\n",
    "\n",
    "dataset.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime uma amostra aleatória\n",
    "\n",
    "dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna em formato de tupla a quantidade de linhas e colunas do dataset\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime informações sobre colunas e uso de memória \n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisando um dataframe com Pandas Profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando o Pandas Profiling\n",
    "\n",
    "!pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando o Pandas Profiling\n",
    "\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o arquivo de dados e construindo o dataframe chamado df\n",
    "\n",
    "arquivo = ('C:/Users/Pc Trabalho/Desktop/Studio Sun/Estudo/DSZ/mdrepo-master/kc_house_data.csv')\n",
    "df = pd.read_csv (arquivo, sep= ',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o Profiling no Jupyter Notebook / Google Colab\n",
    "\n",
    "pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando um relatório HTML\n",
    "\n",
    "profile = pandas_profiling.ProfileReport(df)\n",
    "profile.to_file('report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trabalhando com grandes arquivos**\n",
    "- Quando estamos trabalhando com grandes arquivos temos um grande desafio que é gerenciar a memória\n",
    "\n",
    "- As vezes precisamos manipular uma base de dados muito grande e por isso precisamos trabalhar com arquivos de forma diferente\n",
    "\n",
    "- Uma forma é ler esses arquivos de forma limitada para não consumir toda a memória do servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo as 5 primeiras linhas do arquivo\n",
    "# A diferença deste comando para o head() é que ele abre somente com o número de linhas desejado\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "arquivo = ('C:/Users/Pc Trabalho/Desktop/Studio Sun/Estudo/DSZ/mdrepo-master/kc_house_data.csv')\n",
    "dataset = pd.read_csv(arquivo, sep=',', nrows=5)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O parametro chunksize define quantas linhas o bloco irá ter \n",
    "\n",
    "chunk = pd.read_csv(arquivo, chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimindo tamanho das partes dos arquivos\n",
    "\n",
    "for parte in chunk:\n",
    "  print (len(parte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O parametro chunksize define quantas linhas o bloco irá ter\n",
    "\n",
    "chunk=pd.read_csv(arquivo,chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intera sobre cada parte do dataframe em seguida adicione o valor processado a uma nova coluna do dataset\n",
    "\n",
    "lista=[]\n",
    "for parte in chunk:\n",
    "  lista.append(parte['bedrooms']*2)\n",
    "  dataset['bedrooms']=pd.concat(lista)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mais recursos para trabalhar com grandes bases de dados**\n",
    "\n",
    "---\n",
    "- Tente trabalhar apenas com as colunas que você realmente vai precisar\n",
    "\n",
    "- Atente para o tipo de dado de cada coluna\n",
    "\n",
    "- Visualize qual o separador usado para separar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dica: se estiver no Linux use o comando head para ler as 5 primeiras linhas do arquivo\n",
    "\t#!head -n 5 dataset.csv\n",
    "\n",
    "\n",
    "#Dica: se estiver no Windows abra o prompt de comando do PowerShell e use o comando abaixo\n",
    "\t#gc kc_house_data.csv -head 5 (pesquisar sobre isso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler a base com o parametro nrows\n",
    "\n",
    "df=pd.read_csv('C:/Users/Pc Trabalho/Desktop/Studio Sun/Estudo/DSZ/mdrepo-master/kc_house_data.csv',sep=',',nrows=5 )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporte o nome das colunas para usar no parametro usecols\n",
    "\n",
    "df.columns.tolist()\n",
    "df=pd.read_csv('C:/Users/Pc Trabalho/Desktop/Studio Sun/Estudo/DSZ/mdrepo-master/kc_house_data.csv',usecols=['id','date','price','bedrooms','sqft_living','sqft_lot','floors','waterfront'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo as colunas por posições numéricas em vez de dar o nome das colunas\n",
    "\n",
    "df = pd.read_csv ('C:/Users/Pc Trabalho/Desktop/Studio Sun/Estudo/DSZ/mdrepo-master/kc_house_data.csv', usecols=[0,1,2,3,4,5])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler o arquivo completo e ver o uso de memória\n",
    "\n",
    "df = pd.read_csv ('C:/Users/Pc Trabalho/Desktop/Studio Sun/Estudo/DSZ/mdrepo-master/kc_house_data.csv', sep=',')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo todas as colunas exceto algumas\n",
    "\n",
    "data = 'C:/Users/Pc Trabalho/Desktop/Studio Sun/Estudo/DSZ/mdrepo-master/kc_house_data.csv'\n",
    "df = pd.read_csv (data, usecols = lambda column : column not in ['sqft_living','sqft_lot','floors'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trabalhe com os tipos de dados adequados**\n",
    "\n",
    "- Atenção para os tipos de dados **object**\n",
    "\n",
    "- Dados que são categóricos podem receber o tipo de dados category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo os tipos de dados\n",
    "\n",
    "df.Sex = df.Sex.astype ('category')\n",
    "df.Embarked = df.Embarked.astype ('category')\n",
    "df.Survived = df.Survived.astype ('category')\n",
    "df.Pclass = df.Pclass.astype ('category')\n",
    "df.PassengerId = df.PassengerId.astype ('int32')\n",
    "df.Parch = df.Parch.astype ('int32')\n",
    "df.SibSp = df.SibSp.astype ('int32')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter as colunas em tempo de leitura (garantir que ocupe pouco espaço na memória)\n",
    "\n",
    "data = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv (data, dtype = {'Embarked' : 'category', 'Survived' : 'category', 'Parch' : 'int32'})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consultando e alterando Dataframes**\n",
    "\n",
    "- Podemos fazer consultas em um Dataset\n",
    "\n",
    "- Existem métodos interessantes para fazer consultas usando operadores lógicos (>,<,==)\n",
    "\n",
    "- Além disso podemos fazer consultas usando instruções de agrupamento, por exemplo\n",
    "\n",
    "- Isso da muita flexibilidade para o Cientista de Dados na hora de explorar a base de dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv ('https://raw.githubusercontent.com/minerandodados/mdrepo/master/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta a quantidade de valores únicos\n",
    "\n",
    "pd.value_counts(dataset['bedrooms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O método loc() é usado para visualizar informações do dataset \n",
    "# Este método recebe uma lista por parâmetro e retorna o resultado da consulta\n",
    "# Consulta imóveis com 3 quartos\n",
    "\n",
    "dataset.loc[dataset['bedrooms'] ==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o método loc() com o operador &\n",
    "# Consulta imóveis com 3 quartos e banheiros maior do que 2\n",
    "\n",
    "dataset.loc[(dataset['bedrooms']==3) & (dataset['bathrooms'] > 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O método sort_values() ordena o dataset pela coluna ‘price’ em ordem decrescente\n",
    "# Apenas o retorno da query será ordenado, não a organização do dataset\n",
    "\n",
    "dataset.sort_values (by = 'price', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o método count() para contar o número de linhas de uma query\n",
    "\n",
    "dataset [dataset ['bedrooms'] == 4 ].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alterando um dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando uma coluna ao dataframe\n",
    "\n",
    "dataset ['size'] = (dataset ['bedrooms'] * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o conteúdo da coluna criada\n",
    "\n",
    "dataset ['size'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma função para processamento de dados\n",
    "\n",
    "def categoriza (s):\n",
    "  if s >= 80:\n",
    "    return 'big'\n",
    "  elif s >= 60:\n",
    "    return 'medium'\n",
    "  elif s >= 40:\n",
    "    return 'small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma nova coluna a partir do processamento realizado\n",
    "\n",
    "dataset ['cat_size'] = dataset ['size'].apply (categoriza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando a nova coluna criada\n",
    "\n",
    "dataset ['cat_size'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ve a distribuição da coluna com o método value_counts\n",
    "\n",
    "pd.value_counts (dataset ['cat_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O método drop é usado para excluir dados no dataframe\n",
    "# A opção axis=1 define que queremos excluir uma coluna e não uma linha\n",
    "# O parâmetro inplace define que a alteração irá modificar o objeto em memória\n",
    "\n",
    "dataset.drop (['cat_size'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apagando a coluna size \n",
    "\n",
    "dataset.drop(['size'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o dataset\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropa linhas com bedrooms = 0\n",
    "\n",
    "dataset.drop (dataset[dataset.bedrooms ==0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropa linhas maiores que 30\n",
    "\n",
    "dataset.drop (dataset[dataset.bedrooms > 30].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Percorrendo linhas de um Dataframe Pandas**\n",
    "\n",
    "- Método iterrows() permite percorrer por todas as linhas de um dataframe\n",
    "\n",
    "- Esse método retorna um objeto iterator que contém o índice de cada linha e um cada linha em um dado do tipo série"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "dataset = pd.read_csv ('https://raw.githubusercontent.com/minerandodados/mdrepo/master/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime a primeira linha do objeto iterator\n",
    "\n",
    "next(dataset.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorrendo o dataframe e imprimindo o índice e cada linha\n",
    "\n",
    "for indice, linha in dataset.head(10).iterrows():\n",
    "  print (indice, linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorrendo o dataframe e acessando colunas nomes\n",
    "\n",
    "for indice, linha in dataset.head(10).iterrows():\n",
    "  print (indice, linha ['bedrooms'], linha ['floors'], linha ['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atualizando dataframe ao percorrer linha a linha**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime os 5 primeiros valores de preços antes da atualização\n",
    "\n",
    "dataset.price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorrendo e atualizando linhas de um dataframe\n",
    "# Atualiza o valor da coluna price multiplicando seu valor por 2\n",
    "# É preciso usar o método at()\n",
    "\n",
    "for indice, linha in dataset.iterrows():\n",
    "  dataset.at[indice, 'price'] = linha ['price'] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimindo as 5 primeiras linhas da coluna price\n",
    "\n",
    "dataset.price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Percorrendo um Dataframe com o método itertuples()**\n",
    "\n",
    "- Retorna as linhas e índice em formato de tuplas\n",
    "\n",
    "- Costuma ser mais rápido do que o iterrows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorre o dataframe usando o itertuples()\n",
    "\n",
    "for linha in dataset.head().itertuples():\n",
    "  print (linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime linhas chamando as colunas por nome\n",
    "\n",
    "for linha in dataset.head().itertuples():\n",
    "  print (linha.id, linha.bedroom, linha.price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Values**\n",
    "- Missing Values são valores faltantes em colunas, esses podem ser oriundos de falhas em cargas de dados, falhas em crawlers ou até mesmo corrupção de dados\n",
    "\n",
    "- Missing Values podem ser um problema em várias situações, como por exemplo, algoritmos de machine learning que não trabalham bem com dados faltantes\n",
    "\n",
    "- Estes também podem atrapalhar resultados de análises \n",
    "\n",
    "- Vamos aprender como encontrar missing values na base de dados e como manipular esses valores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando arquivo CSV \n",
    "\n",
    "arquivo = 'https://raw.githubusercontent.com/minerandodados/mdrepo/master/kc_house_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(arquivo, sep = ',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultando linhas com valores faltantes\n",
    "\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Com este comando, removemos todas as linhas onde tenha pelo menos um registro faltante em algum atributo \n",
    "\n",
    "dataset.dropna (inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# É possível ainda, remover somente linhas que estejam, com valores faltantes em todas as colunas\n",
    "\n",
    "dataset.dropna (how = 'all', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preenche com a média dos valores da coluna floors os valores null\n",
    "\n",
    "dataset ['floors'].fillna (dataset ['floors'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preenche com 1 os valores null da coluna bedrooms\n",
    "\n",
    "dataset ['bedrooms'].fillna (1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualização de dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota em um gráfico de barras o preço dos imóveis\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "dataset ['price'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota em um gráfico de dispersão o preço e o número de quartos de imóveis\n",
    "\n",
    "dataset.plot (x = 'bedrooms', y = 'price', kind = 'scatter', title = 'bedroom x price', color ='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota em gráfico de dispersão o preço e o número de banheiros\n",
    "\n",
    "dataset.plot (x = 'bathrooms', y = 'price', kind = 'scatter', color = 'y')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}