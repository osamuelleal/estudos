{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python para Análise de Dados - Pandas 2**\n",
    "\n",
    "- Iremos trabalhar com base de imóveis do site Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importe a biblioteca Pandas\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo a base de dados\n",
    "\n",
    "arquivo = \"https://raw.githubusercontent.com/minerandodados/mdrepo/master/kc_house_data.csv\"\n",
    "dataset = pd.read_csv(arquivo, sep= \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota um histograma com a coluna price com 30 bins na cor vermelho\n",
    "\n",
    "# O uso do ';' no final do comando, é para não apresentar o log\n",
    "\n",
    "%matplotlib inline\n",
    "dataset ['price'].hist(bins=30, color='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota histogramas das colunas bedrooms e bathrooms lado a lado na cor verde\n",
    "\n",
    "%matplotlib inline\n",
    "dataset [['bedrooms','bathrooms']].hist(bins=30, alpha=0.5, color='green');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estatística descritiva**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o valor médio da coluna bedrooms\n",
    "\n",
    "dataset['bedrooms'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o valor máximo da coluna bedrooms\n",
    "\n",
    "dataset['bedrooms'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o valor mínimo da coluna bedrooms\n",
    "\n",
    "dataset['bedrooms'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime o desvio padrão da coluna bedrooms\n",
    "\n",
    "dataset['bedrooms'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime a simetria da coluna bedrooms\n",
    "\n",
    "dataset['bedrooms'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esse método retorna o valor de simetria de cada coluna do dataset \n",
    "# Um valor 0 significa uma distribuição simétrica\n",
    "# Um valor maior ou menor que 0, significa uma distribuição assimétrica\n",
    "# Valores acima de 0 podemos dizer que tem uma assimetria positiva\n",
    "# Valores abaixo de 0 uma assimetria negativa\n",
    "# Isso quer dizer que valores muito acima de 0 indicam que existem mais valores acima da média\n",
    "# Valores muito abaixo de 0 indicam que existem mais valores abaixo da média\n",
    "\n",
    "dataset.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gráficos de BoxPlot, correlação de variáveis**\n",
    "**Extraindo Insights**\n",
    "\n",
    "- Vamos agora trabalhar com um tipo de gráfico muito interessante \n",
    "\n",
    "- Os gráficos do tipo Boxplot são excelentes ferramentas de análise de dados, principalmente para identificar outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "arquivo = \"https://raw.githubusercontent.com/minerandodados/mdrepo/master/kc_house_data.csv\"\n",
    "dataset = pd.read_csv(arquivo, sep= \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota gráfico do tipo boxplot da coluna bedrooms\n",
    "# Esse gráfico é muito rico e é possível visualizar outliers\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "dataset.boxplot(column='bedrooms');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando os estilos de gráficos disponíveis\n",
    "\n",
    "matplotlib.style.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota boxplot da coluna 'price' por números de quarto\n",
    "\n",
    "%matplotlib inline\n",
    "dataset.boxplot(column='price', by='bedrooms');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime a correlação de todas as colunas do dataframe (person) \n",
    "\n",
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime a correlação de Spearman (esta leva em consideração a correção positiva e negativa)\n",
    "\n",
    "dataset.corr('spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime a correção de algumas colunas\n",
    "\n",
    "dataset[['bedrooms', 'bathrooms', 'sqft_living', 'floors', 'waterfront', 'grade', 'price']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando a correlação de determinadas colunas \n",
    "\n",
    "%matplotlib inline\n",
    "dataset[['sqft_living', 'waterfront', 'grade', 'price']].corr().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabela Pivot, Manipulação de planilhas do Excel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabelas Pivot são úteis para fazer agrupamento de dados\n",
    "# Conta a quantidade de imóveis agrupados pelas colunas waterfront e floors\n",
    "# O parametro index informa as colunas que serão usadas para agregação\n",
    "# O parâmetro aggfunc é usado para definir a função de agregação, que poderia ser uma média por exemplo\n",
    "# O parâmetro margins=True calcula a quantidade total no final da tabela\n",
    "\n",
    "# Muito interessante a performance dessa operação\n",
    "\n",
    "dataset.pivot_table('id', index=['waterfront', 'floors'], aggfunc='count', margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CrossTab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstab ou tabulação cruzada\n",
    "# Essa funcionalidade cruza valores das variáveis\n",
    "# Nesse exemplo podemos ver qual a distribuição dos imóveis por número de quartos com relação a sua condição\n",
    "# Podemos ver que imóveis com 3 quartos estão mais na condição 5\n",
    "\n",
    "pd.crosstab(dataset['bedrooms'], dataset['condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota a tabulação cruzada\n",
    "# Usamos o método plot() com um gráfico de barras\n",
    "\n",
    "table = pd.crosstab(dataset['bedrooms'],dataset['condition'])\n",
    "table.plot(kind='bar', width= 1.0, color =['red','yellow', 'orange', 'blue', 'green'], title = 'condition by Bedrooms', grid=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trabalhando com Excel**\n",
    "\n",
    "- Com o Pandas podemos trabalhar com o Excel\n",
    "\n",
    "- Isso é muito bom pois, sabemos sabemos que temos muita informação nos dias de hoje em planilhas do excel\n",
    "\n",
    "- Diante disso você pode usar o pandas para manipular planilhas do Excel e até mesmo gerar novas planilhas a partir de outros dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo uma planilha do Excel no Pandas\n",
    "\n",
    "dataframe_excel = pd.read_excel('C:/Users/Pc Trabalho/Desktop/Studio Sun/Estudo/DSZ/mdrepo-master/Controle-de-Atividades-2.0.xlsx', sheet_name=0, header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o arquivo indexando pela coluna 'Estado Atual'\n",
    "\n",
    "arquivo = 'C:/Users/Pc Trabalho/Desktop/Studio Sun/Estudo/DSZ/mdrepo-master/Controle-de-Atividades-2.0.xlsx'\n",
    "dataframe_excel = pd.read_excel(arquivo, sheet_name=0, header=1, index_col=3)\n",
    "\n",
    "dataframe_excel.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenando o dataframe pela coluna de índice\n",
    "\n",
    "dataframe_excel.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gerando planilhas a partir de dataframes** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vou usar o dataset de imóveis para gerar uma planilha\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando uma planilha com deteminadas colunas\n",
    "\n",
    "colunas = ['id', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'floors', 'waterfront']\n",
    "dataset[colunas].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escrevendo no disco a planilha sem o valor do índice\n",
    "\n",
    "dataset[colunas].to_excel('planilha_pandas.xls', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mesclando Dados a partir de diversos DataFrames**\n",
    "\n",
    "- Consulta os dados em mais de 1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a biblioteca Pandas\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os datasets de pedidos\n",
    "\n",
    "orders = pd.read_csv('C:/Users/Pc Trabalho/Desktop/Studio Sun/Estudo/olist_orders_dataset.csv')\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset de itens pedidos\n",
    "\n",
    "orders_items = pd.read_csv('C:/Users/Pc Trabalho/Desktop/Studio Sun/Estudo/olist_order_items_dataset.csv')\n",
    "orders_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opções de Merge**\n",
    "\n",
    "Tipos de Join (ligações)\n",
    "\n",
    "- INNER JOIN (padrão): retorna apenas os registros que contém a mesma palavra chave em ambos os dataframes\n",
    "\n",
    "- LEFT JOIN: retorna todos os registros do dataframe à esquerda independente se contém um correspondente à direita\n",
    "\n",
    "- RIGHT JOIN: retorna todos os registros do dataframe à direita indepentende se contém um correspondente à esquerda\n",
    "\n",
    "- OUTER JOIN OU FULL JOIN: retorna todos os registros de ambos os dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image ('C:/Users/Pc Trabalho/Desktop/Studio Sun/Estudo/DSZ/PDF AULAS/MODULO5/materiais-de-apoio-pandas-merge-datasets/joins.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consultando os dados nos dois datasets e ligando através da chave order_id**\n",
    "\n",
    "> Selecionando os atributos do dataset orders (pedidos)\n",
    "\n",
    "- order_id (id do pedido)\n",
    "- order_status (status do pedido)\n",
    "- order_approved_at (data e hora da aprovação do pedido)\n",
    "\n",
    "> Selecionando os atributos do dataset orders_items (itens do pedido)\n",
    "\n",
    "- product_id (id do produto)\n",
    "- seller_id (id do vendedor)\n",
    "- price (preço do produto)\n",
    "- freight_value (valor do frete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = pd.merge (orders[['order_id', 'order_status', 'order_approved_at']],\n",
    "                  orders_items[['order_id', 'product_id', 'seller_id', 'price', 'freight_value']], on= 'order_id'\n",
    "                  )\n",
    "\n",
    "query.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta todos os pedidos independente se contém itens associados (left join)\n",
    "\n",
    "query = pd.merge (orders[['order_id', 'order_status', 'order_approved_at']],\n",
    "                  orders_items[['order_id', 'product_id', 'seller_id', 'price', 'freight_value']], on= 'order_id', how= 'left'\n",
    "                  )\n",
    "\n",
    "query.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saber quantos valores vieram nulos na correlação\n",
    "# Se aparecer 0 é porque vieram todos os valores\n",
    "\n",
    "query.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta todos os pedidos independente se contém itens associados (right join)\n",
    "\n",
    "query = pd.merge (orders[['order_id', 'order_status', 'order_approved_at']],\n",
    "                  orders_items[['order_id', 'product_id', 'seller_id', 'price', 'freight_value']], on= 'order_id', how= 'right'\n",
    "                  )\n",
    "\n",
    "query.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta todos os registros no dataframe (Outer join)\n",
    "\n",
    "query = pd.merge (orders[['order_id', 'order_status', 'order_approved_at']],\n",
    "                  orders_items[['order_id', 'product_id', 'seller_id', 'price', 'freight_value']], on= 'order_id', how= 'outer'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criando um DataFrame a partir de uma Tabela do Banco de Dados**\n",
    "\n",
    "> Instalação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engine de conexão ao Banco de Dados MySQL\n",
    "\n",
    "Sintaxe:\n",
    "engine = sqlalchemy.create_engine( 'mysql+drive://usuario:senha@ip-servidor:porta/banco-de-dados')\n",
    "\n",
    "Documentação do SQL Alchemy\n",
    "\n",
    "https://docs.sqlalchemy.org/en/13/core/engines.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a conexão\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:freestepnina@localhost:3306/employees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Método: read_sql_table\n",
    "\n",
    "Parâmetros do método read_sql_table\n",
    "\n",
    "- table_name = nome da tabela onde será feita a leitura dos dados\n",
    "- con = objeto conexão criado pelo SQLAlchemy \n",
    "- schema = schema onde a tabela será armazenada\n",
    "- index_col = coluna a ser definida como index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Lendo toda a tabela Employees e transformando em dataframe\n",
    "\n",
    " df = pd.read_sql_table ('employees', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listando os dados e informações dos atributos\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo apenas algumas colunas da tabela\n",
    "\n",
    "df = pd.read_sql_table ('employees', engine , columns=['first_name','last_name'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Método: read_sql_query**\n",
    "\n",
    "- sql = String Sql Query que deverá ser executada para retornar conjuntos de dados\n",
    "- con = objeto conexão criado pelo SQLAlchemy \n",
    "- index_col = coluna a ser definida como index\n",
    "- params = lista de parametros para serem passados ao método"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um DataFrame a partir de uma query ao banco de dados\n",
    "\n",
    "df = pd.read_sql_query ('select * from employees', engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um dataframe a partir de uma query ao banco de dados utilizando a coluna emp_no como index\n",
    "\n",
    "df_index = pd.read_sql_query ('select * from employees', engine, index_col = 'emp_no')\n",
    "df_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando um DataFrame a partir de uma query utilizando parametros dinamicos\n",
    "query = 'SELECT first_name, last_name' \\\n",
    "        'FROM employees' \\\n",
    "        'WHERE first_name = %s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_sql_query (query, engine, params =['Mary'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Método: read_sql**\n",
    "\n",
    "Faz o roteamento entre os métodos read_table e read_sql_query\n",
    "\n",
    "Parâmetros do método read_sql\n",
    "\n",
    "- sql: String Sql Query que deverá ser executada para retornar o conjunto de dados\n",
    "- con = objeto conexão criado pelo SQLAlchemy\n",
    "- index_col = coluna a ser definida como index\n",
    "- params = lista de parametros para serem passados ao método"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  dept_no         dept_name\n0    d009  Customer Service\n1    d005       Development\n2    d002           Finance\n3    d003   Human Resources\n4    d001         Marketing",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dept_no</th>\n      <th>dept_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>d009</td>\n      <td>Customer Service</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>d005</td>\n      <td>Development</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>d002</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>d003</td>\n      <td>Human Resources</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>d001</td>\n      <td>Marketing</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "# Criando o DataFrame passando apenas o nome da tabela para o método\n",
    "\n",
    "df = pd.read_sql ('departments', engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  dept_no         dept_name\n0    d009  Customer Service\n1    d005       Development\n2    d002           Finance\n3    d003   Human Resources\n4    d001         Marketing",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dept_no</th>\n      <th>dept_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>d009</td>\n      <td>Customer Service</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>d005</td>\n      <td>Development</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>d002</td>\n      <td>Finance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>d003</td>\n      <td>Human Resources</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>d001</td>\n      <td>Marketing</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "# Criando o dataframe a partir de uma query\n",
    "\n",
    "df = pd.read_sql ('SELECT * FROM departments', engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Método: to_sql**\n",
    "\n",
    "Escreve o dataframe para o banco de dados relacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   3    ?  alfa-romero  gas  std   two  convertible  rwd  front  88.60  ...  \\\n0  3    ?  alfa-romero  gas  std   two  convertible  rwd  front   88.6  ...   \n1  1    ?  alfa-romero  gas  std   two    hatchback  rwd  front   94.5  ...   \n2  2  164         audi  gas  std  four        sedan  fwd  front   99.8  ...   \n3  2  164         audi  gas  std  four        sedan  4wd  front   99.4  ...   \n4  2    ?         audi  gas  std   two        sedan  fwd  front   99.8  ...   \n\n   130  mpfi  3.47  2.68  9.00  111  5000  21  27  13495  \n0  130  mpfi  3.47  2.68   9.0  111  5000  21  27  16500  \n1  152  mpfi  2.68  3.47   9.0  154  5000  19  26  16500  \n2  109  mpfi  3.19  3.40  10.0  102  5500  24  30  13950  \n3  136  mpfi  3.19  3.40   8.0  115  5500  18  22  17450  \n4  136  mpfi  3.19  3.40   8.5  110  5500  19  25  15250  \n\n[5 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>3</th>\n      <th>?</th>\n      <th>alfa-romero</th>\n      <th>gas</th>\n      <th>std</th>\n      <th>two</th>\n      <th>convertible</th>\n      <th>rwd</th>\n      <th>front</th>\n      <th>88.60</th>\n      <th>...</th>\n      <th>130</th>\n      <th>mpfi</th>\n      <th>3.47</th>\n      <th>2.68</th>\n      <th>9.00</th>\n      <th>111</th>\n      <th>5000</th>\n      <th>21</th>\n      <th>27</th>\n      <th>13495</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>?</td>\n      <td>alfa-romero</td>\n      <td>gas</td>\n      <td>std</td>\n      <td>two</td>\n      <td>convertible</td>\n      <td>rwd</td>\n      <td>front</td>\n      <td>88.6</td>\n      <td>...</td>\n      <td>130</td>\n      <td>mpfi</td>\n      <td>3.47</td>\n      <td>2.68</td>\n      <td>9.0</td>\n      <td>111</td>\n      <td>5000</td>\n      <td>21</td>\n      <td>27</td>\n      <td>16500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>?</td>\n      <td>alfa-romero</td>\n      <td>gas</td>\n      <td>std</td>\n      <td>two</td>\n      <td>hatchback</td>\n      <td>rwd</td>\n      <td>front</td>\n      <td>94.5</td>\n      <td>...</td>\n      <td>152</td>\n      <td>mpfi</td>\n      <td>2.68</td>\n      <td>3.47</td>\n      <td>9.0</td>\n      <td>154</td>\n      <td>5000</td>\n      <td>19</td>\n      <td>26</td>\n      <td>16500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>164</td>\n      <td>audi</td>\n      <td>gas</td>\n      <td>std</td>\n      <td>four</td>\n      <td>sedan</td>\n      <td>fwd</td>\n      <td>front</td>\n      <td>99.8</td>\n      <td>...</td>\n      <td>109</td>\n      <td>mpfi</td>\n      <td>3.19</td>\n      <td>3.40</td>\n      <td>10.0</td>\n      <td>102</td>\n      <td>5500</td>\n      <td>24</td>\n      <td>30</td>\n      <td>13950</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>164</td>\n      <td>audi</td>\n      <td>gas</td>\n      <td>std</td>\n      <td>four</td>\n      <td>sedan</td>\n      <td>4wd</td>\n      <td>front</td>\n      <td>99.4</td>\n      <td>...</td>\n      <td>136</td>\n      <td>mpfi</td>\n      <td>3.19</td>\n      <td>3.40</td>\n      <td>8.0</td>\n      <td>115</td>\n      <td>5500</td>\n      <td>18</td>\n      <td>22</td>\n      <td>17450</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>?</td>\n      <td>audi</td>\n      <td>gas</td>\n      <td>std</td>\n      <td>two</td>\n      <td>sedan</td>\n      <td>fwd</td>\n      <td>front</td>\n      <td>99.8</td>\n      <td>...</td>\n      <td>136</td>\n      <td>mpfi</td>\n      <td>3.19</td>\n      <td>3.40</td>\n      <td>8.5</td>\n      <td>110</td>\n      <td>5500</td>\n      <td>19</td>\n      <td>25</td>\n      <td>15250</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "# Carregando a base de dados e criando o dataframe\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/minerandodados/mdrepo/master/automobile.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parametros do método to_sql**\n",
    "\n",
    "- name = nome da tabela que será criada no SGDB\n",
    "- con = objeto conexão criado pelo SQLAlchemy\n",
    "- schema = nome do schema onde será criada a tabela\n",
    "- if_exists = comportamento caso a tabela exista no SGBD\n",
    "- index = escreve o índice do dataframe como uma coluna na tabela\n",
    "- index_label = nome da coluna do índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a tabela no Banco de Dados a partir do Dataframe\n",
    "\n",
    "df.to_sql (name = 'tb_automobile', con = engine,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a tabela no Banco de Dados a partir do Dataframe sem a coluna indice\n",
    "\n",
    "df.to_sql (name = 'tb_automobile', con = engine, index = False, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}